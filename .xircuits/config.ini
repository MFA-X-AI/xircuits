[DEV]
BASE_PATH = xai_components

[SERVER]
IP_ADD = http://127.0.0.1
PORT = 5000

[CONFIGURATION]
SPARK = CPU 
        GPU
        VE

[CPU]
name =  CPU
command = $SPARK_HOME/bin/spark-submit \
            --py-files venv_pyspark_cyclone.zip \
            --archives venv_pyspark_cyclone.zip \
            --master yarn \
            --conf spark.yarn.appMasterEnv.LD_LIBRARY_PATH='/usr/local/cuda-11.2/targets/x86_64-linux/lib/:$LD_LIBRARY_PATH' \ 
            --num-executors=8 --executor-cores=1 --executor-memory=10G --driver-memory=10G \
            --name CPU_CPU_mode \
            --deploy-mode cluster \
            --conf spark.rpc.message.maxSize=1024 \
            --conf spark.driver.maxResultSize=10G 
msg = Running Spark Submit using CPU 
url = http://localhost:8088/

[GPU]
name = GPU
command = $SPARK_HOME/bin/spark-submit \
            --py-files venv_pyspark_cyclone.zip \
            --archives venv_pyspark_cyclone.zip \
            --master yarn \
            --conf spark.yarn.appMasterEnv.LD_LIBRARY_PATH='/usr/local/cuda-11.2/targets/x86_64-linux/lib/:$LD_LIBRARY_PATH' \
            --num-executors=16 --executor-cores=1 --executor-memory=7G --driver-memory=8G \
            --name VE_GPU_mode \
            --deploy-mode cluster \
            --jars /opt/cyclone/spark-cyclone-sql-plugin.jar \
            --conf spark.executor.extraClassPath=/opt/cyclone/spark-cyclone-sql-plugin.jar \
            --conf spark.plugins=com.nec.spark.AuroraSqlPlugin \
            --conf spark.com.nec.spark.kernel.directory=/opt/spark/work/cyclone \
            --conf spark.sql.columnVector.offheap.enabled=true \
            --conf spark.executor.resource.ve.amount=2 \
            --conf spark.executor.resource.ve.discoveryScript=/opt/spark/getVEsResources.sh \
            --conf spark.executorEnv.VE_OMP_NUM_THREADS=1 \
            --conf spark.rpc.message.maxSize=1024 \
            --conf spark.driver.maxResultSize=4G \
            --conf spark.locality.wait=0 \
            --conf spark.com.nec.spark.aggregate-on-ve=false \
            --conf spark.com.nec.spark.sort-on-ve=true \
            --conf spark.com.nec.spark.project-on-ve=false \
            --conf spark.com.nec.spark.filter-on-ve=true \
            --conf spark.com.nec.spark.exchange-on-ve=true \
            --conf spark.com.nec.spark.join-on-ve=true \
            --conf spark.com.nec.spark.pass-through-project=false \
            --conf spark.com.nec.spark.fail-fast=false \
            --conf spark.sql.adaptive.enabled=true \
            --conf spark.sql.adaptive.coalescePartitions.enabled=true \
            --conf spark.com.nec.spark.amplify-batches=true \
            --conf spark.com.nec.spark.ve.columnBatchSize=512000 \
            --conf spark.com.nec.spark.ve.targetBatchSizeMb=256 \
            --conf spark.sql.inMemoryColumnarStorage.batchSize=512000 
msg = Running Spark Submit using GPU
url = http://localhost:8088/

[VE]
name =  VE
command = $SPARK_HOME/bin/spark-submit \
                --py-files venv_TF_VE.zip \
                --archives venv_TF_VE.zip \
                --master yarn \
                --conf spark.yarn.appMasterEnv.LD_LIBRARY_PATH='/usr/local/cuda-11.2/targets/x86_64-linux/lib/:$LD_LIBRARY_PATH' \
                --num-executors=8 --executor-cores=1 --executor-memory=7G --driver-memory=8G \
                --name VE_VE_mode \
                --deploy-mode cluster \
                --jars /opt/cyclone/spark-cyclone-sql-plugin.jar \
                --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON='/usr/local/bin/python3.8' \
                --conf spark.yarn.appMasterEnv.PYSPARK_DRIVER_PYTHON='/usr/local/bin/python3.8' \
                --conf spark.executor.extraClassPath=/opt/cyclone/spark-cyclone-sql-plugin.jar \
                --conf spark.plugins=com.nec.spark.AuroraSqlPlugin \
                --conf spark.com.nec.spark.kernel.directory=/opt/spark/work/cyclone \
                --conf spark.sql.columnVector.offheap.enabled=true \
                --conf spark.executor.resource.ve.amount=1 \
                --conf spark.executor.resource.ve.discoveryScript=/opt/spark/getVEsResources.sh \
                --conf spark.executorEnv.VE_OMP_NUM_THREADS=1 \
                --conf spark.rpc.message.maxSize=1024 \
                --conf spark.driver.maxResultSize=4G \
                --conf spark.locality.wait=0 \
                --conf spark.com.nec.spark.aggregate-on-ve=false \
                --conf spark.com.nec.spark.sort-on-ve=true \
                --conf spark.com.nec.spark.project-on-ve=false \
                --conf spark.com.nec.spark.filter-on-ve=true \
                --conf spark.com.nec.spark.exchange-on-ve=true \
                --conf spark.com.nec.spark.join-on-ve=true \
                --conf spark.com.nec.spark.pass-through-project=false \
                --conf spark.com.nec.spark.fail-fast=false \
                --conf spark.sql.adaptive.enabled=true \
                --conf spark.sql.adaptive.coalescePartitions.enabled=true \
                --conf spark.com.nec.spark.amplify-batches=true \
                --conf spark.com.nec.spark.ve.columnBatchSize=512000 \
                --conf spark.com.nec.spark.ve.targetBatchSizeMb=256 \
                --conf spark.sql.inMemoryColumnarStorage.batchSize=512000 
msg = Running Spark Submit using VE
url = http://localhost:8088/
